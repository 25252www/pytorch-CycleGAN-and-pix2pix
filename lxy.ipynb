{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意切换环境\n",
    "source activate solaris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/liuxiangyu/pytorch-CycleGAN-and-pix2pix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python gen_span2fused_dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold_A] =  ./datasets/span2fused/A\n",
      "[fold_B] =  ./datasets/span2fused/B\n",
      "[fold_AB] =  ./datasets/span2fused/AB\n",
      "[num_imgs] =  1000000\n",
      "[use_AB] =  False\n",
      "[no_multiprocessing] =  True\n",
      "split = test, use 3401/3401 images\n",
      "split = test, number of images = 3401\n",
      "  0%|                                                  | 0/3401 [00:00<?, ?it/s]np.shape(im_A) (900, 900)\n",
      "np.shape(im_B) (900, 900)\n",
      "  0%|                                          | 1/3401 [00:00<09:38,  5.87it/s]np.shape(im_A) (900, 900)\n",
      "np.shape(im_B) (900, 900)\n",
      "  0%|                                          | 1/3401 [00:00<17:16,  3.28it/s]\n",
      "split = train, use 2696/2696 images\n",
      "split = train, number of images = 2696\n",
      "  0%|                                                  | 0/2696 [00:00<?, ?it/s]np.shape(im_A) (900, 900)\n",
      "np.shape(im_B) (900, 900)\n",
      "  0%|                                          | 1/2696 [00:00<06:42,  6.69it/s]np.shape(im_A) (900, 900)\n",
      "np.shape(im_B) (900, 900)\n",
      "  0%|                                          | 1/2696 [00:00<13:15,  3.39it/s]\n",
      "split = val, use 705/705 images\n",
      "split = val, number of images = 705\n",
      "  0%|                                                   | 0/705 [00:00<?, ?it/s]np.shape(im_A) (900, 900)\n",
      "np.shape(im_B) (900, 900)\n",
      "np.shape(im_A) (900, 900)\n",
      "np.shape(im_B) (900, 900)\n",
      "  0%|                                           | 1/705 [00:00<02:54,  4.02it/s]\n"
     ]
    }
   ],
   "source": [
    "# 创建aligned数据集\n",
    "!python ./datasets/combine_A_and_B.py --fold_A ./datasets/span2fused/A --fold_B ./datasets/span2fused/B --fold_AB ./datasets/span2fused/AB --no_multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --dataroot ./datasets/span2fused/AB --name span2fused --model pix2pix --direction AtoB"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d462411eb9638572f7bdc354db1f2d4fabd664429bf2ae3d442bc35bb08570fb"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('solaris')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
